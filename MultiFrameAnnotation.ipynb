{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "from torchvision import models\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to python models/MultiFrameCNN.ipynb\n",
    "from models import MultiFrameCNN\n",
    "reload(MultiFrameCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to python dataset/VideoSequenceDataset.ipynb\n",
    "from dataset import VideoSequenceDataset\n",
    "reload(VideoSequenceDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to python models/SuperMobile.ipynb\n",
    "from models import SuperMobile\n",
    "reload(SuperMobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to python models/ShuffleNet.ipynb\n",
    "from models import ShuffleNet\n",
    "reload(ShuffleNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testDataset, cuda=True):\n",
    "    model = model.eval()\n",
    "    tot = 0\n",
    "    cor = 0\n",
    "    for i, (batch, labels) in enumerate(testDataset):\n",
    "        if cuda:\n",
    "            batch = batch.cuda()\n",
    "            labels = labels.cuda()\n",
    "        outputs=model(Variable(batch))\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        tot += labels.size(0)\n",
    "        cor += (pred == labels).sum()\n",
    "        \n",
    "    print(cor, \"/\", tot, \" : \", cor*1.0/tot*100, \"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, trainDataset, valDataset, trans, nbepoch=5, cuda=True):\n",
    "    #criterion = nn.CrossEntropyLoss(Variable(torch.Tensor([1/5.2,1/5.2,1/5.2,1/5.2,1/5.2,0.2/5.2])))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    for epoch in range(nbepoch):\n",
    "        print(\"Epoch \", epoch, \"precision : \")\n",
    "        test(model, valDataset, cuda)\n",
    "        \n",
    "        model = model.train()\n",
    "        lo = 0\n",
    "        for i, (batch,labels) in enumerate(trainDataset):\n",
    "            if cuda:\n",
    "                batch = batch.cuda()\n",
    "                labels = labels.cuda()\n",
    "            \n",
    "            outputs = model(Variable(batch))\n",
    "            #label = torch.LongTensor([gesture])\n",
    "            loss = criterion(outputs, Variable(labels))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lo += loss.data[0]\n",
    "            if i%10 == 0:\n",
    "                print(i,' : ', lo/10.0)\n",
    "                lo = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = MultiFrameCNN.MultiFrameResNet(MultiFrameCNN.BasicBlock, [2,2,2,2], sequence=1, num_classes=27, groups=1)\n",
    "#with 3 frame, and 3 groups and skip 1: accuracy 100%\n",
    "#model = MultiFrameCNN.DummyMultiFrame()\n",
    "#model = MultiFrameCNN.MultiFrameCNN(nbClasse=6,nbFrame=3)\n",
    "#model = MultiFrameCNN.MultiFrameCNN(3) -> 58,333%\n",
    "#model.copyParameters(models.alexnet(pretrained=True))\n",
    "#model = models.AlexNet(num_classes=6)\n",
    "#model = model.cuda()\n",
    "#model=SuperMobile.SuperMobile()\n",
    "#model=SuperMobile.DenseMobile(in_channel=3, num_classes=27, nb_frames=3)\n",
    "#model=SuperMobile.DenseMobile(nb_frames=3)\n",
    "model = ShuffleNet.ShuffleNet(num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1, \n",
    "            padding=1, bias=True, groups=1):    \n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels, \n",
    "        out_channels, \n",
    "        kernel_size=3, \n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        bias=bias,\n",
    "        groups=groups)\n",
    "\n",
    "\n",
    "def conv1x1(in_channels, out_channels, groups=1):\n",
    "    \"\"\"1x1 convolution with padding\n",
    "    - Normal pointwise convolution When groups == 1\n",
    "    - Grouped pointwise convolution when groups > 1\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels, \n",
    "        out_channels, \n",
    "        kernel_size=1, \n",
    "        groups=groups,\n",
    "        stride=1)\n",
    "\n",
    "class ShuffleUnit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, groups=3,\n",
    "                 grouped_conv=True, combine='add'):\n",
    "        \n",
    "        super(ShuffleUnit, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.grouped_conv = grouped_conv\n",
    "        self.combine = combine\n",
    "        self.groups = groups\n",
    "        self.bottleneck_channels = self.out_channels // 4\n",
    "\n",
    "        # define the type of ShuffleUnit\n",
    "        if self.combine == 'add':\n",
    "            # ShuffleUnit Figure 2b\n",
    "            self.depthwise_stride = 1\n",
    "            self._combine_func = self._add\n",
    "        elif self.combine == 'concat':\n",
    "            # ShuffleUnit Figure 2c\n",
    "            self.depthwise_stride = 2\n",
    "            self._combine_func = self._concat\n",
    "            \n",
    "            # ensure output of concat has the same channels as \n",
    "            # original output channels.\n",
    "            self.out_channels -= self.in_channels\n",
    "        else:\n",
    "            raise ValueError(\"Cannot combine tensors with \\\"{}\\\"\" \\\n",
    "                             \"Only \\\"add\\\" and \\\"concat\\\" are\" \\\n",
    "                             \"supported\".format(self.combine))\n",
    "\n",
    "        # Use a 1x1 grouped or non-grouped convolution to reduce input channels\n",
    "        # to bottleneck channels, as in a ResNet bottleneck module.\n",
    "        # NOTE: Do not use group convolution for the first conv1x1 in Stage 2.\n",
    "        self.first_1x1_groups = self.groups if grouped_conv else 1\n",
    "\n",
    "        self.g_conv_1x1_compress = self._make_grouped_conv1x1(\n",
    "            self.in_channels,\n",
    "            self.bottleneck_channels,\n",
    "            self.first_1x1_groups,\n",
    "            batch_norm=True,\n",
    "            relu=True\n",
    "            )\n",
    "\n",
    "        # 3x3 depthwise convolution followed by batch normalization\n",
    "        self.depthwise_conv3x3 = conv3x3(\n",
    "            self.bottleneck_channels, self.bottleneck_channels,\n",
    "            stride=self.depthwise_stride, groups=self.bottleneck_channels)\n",
    "        self.bn_after_depthwise = nn.BatchNorm2d(self.bottleneck_channels)\n",
    "\n",
    "        # Use 1x1 grouped convolution to expand from \n",
    "        # bottleneck_channels to out_channels\n",
    "        self.g_conv_1x1_expand = self._make_grouped_conv1x1(\n",
    "            self.bottleneck_channels,\n",
    "            self.out_channels,\n",
    "            self.groups,\n",
    "            batch_norm=True,\n",
    "            relu=False\n",
    "            )\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _add(x, out):\n",
    "        # residual connection\n",
    "        return x + out\n",
    "\n",
    "    \n",
    "    def _channel_shuffle(self, x, groups):\n",
    "        batchsize, num_channels, height, width = x.data.size()\n",
    "\n",
    "        channels_per_group = num_channels // groups\n",
    "        x = x.view(batchsize, groups, channels_per_group, height, width) #add a new dimension\n",
    "\n",
    "        x = torch.transpose(x, 1, 2).contiguous()\n",
    "        return x.view(batchsize, -1, height, width)\n",
    "\n",
    "    @staticmethod\n",
    "    def _concat(x, out):\n",
    "        # concatenate along channel axis\n",
    "        return torch.cat((x, out), 1)\n",
    "\n",
    "\n",
    "    def _make_grouped_conv1x1(self, in_channels, out_channels, groups,\n",
    "        batch_norm=True, relu=False):\n",
    "\n",
    "        modules = OrderedDict()\n",
    "\n",
    "        conv = conv1x1(in_channels, out_channels, groups=groups)\n",
    "        modules['conv1x1'] = conv\n",
    "\n",
    "        if batch_norm:\n",
    "            modules['batch_norm'] = nn.BatchNorm2d(out_channels)\n",
    "        if relu:\n",
    "            modules['relu'] = nn.ReLU()\n",
    "        if len(modules) > 1:\n",
    "            return nn.Sequential(modules)\n",
    "        else:\n",
    "            return conv\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # save for combining later with output\n",
    "        residual = x\n",
    "\n",
    "        if self.combine == 'concat':\n",
    "            residual = F.avg_pool2d(residual, kernel_size=3, \n",
    "                stride=2, padding=1)\n",
    "\n",
    "        out = self.g_conv_1x1_compress(x)\n",
    "        out = self._channel_shuffle(out, self.groups)\n",
    "        out = self.depthwise_conv3x3(out)\n",
    "        out = self.bn_after_depthwise(out)\n",
    "        out = self.g_conv_1x1_expand(out)\n",
    "        \n",
    "        out = self._combine_func(residual, out)\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class ShuffleNet(nn.Module):\n",
    "    \"\"\"ShuffleNet implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, groups=3, in_channels=3, num_classes=1000):\n",
    "        \"\"\"ShuffleNet constructor.\n",
    "        Arguments:\n",
    "            groups (int, optional): number of groups to be used in grouped \n",
    "                1x1 convolutions in each ShuffleUnit. Default is 3 for best\n",
    "                performance according to original paper.\n",
    "            in_channels (int, optional): number of channels in the input tensor.\n",
    "                Default is 3 for RGB image inputs.\n",
    "            num_classes (int, optional): number of classes to predict. Default\n",
    "                is 1000 for ImageNet.\n",
    "        \"\"\"\n",
    "        super(ShuffleNet, self).__init__()\n",
    "\n",
    "        self.groups = groups\n",
    "        self.stage_repeats = [3, 7, 3]\n",
    "        self.in_channels =  in_channels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # index 0 is invalid and should never be called.\n",
    "        # only used for indexing convenience.\n",
    "        if groups == 1:\n",
    "            self.stage_out_channels = [-1, 24, 144, 288, 567]\n",
    "        elif groups == 2:\n",
    "            self.stage_out_channels = [-1, 24, 200, 400, 800]\n",
    "        elif groups == 3:\n",
    "            self.stage_out_channels = [-1, 24, 240, 480, 960]\n",
    "        elif groups == 4:\n",
    "            self.stage_out_channels = [-1, 24, 272, 544, 1088]\n",
    "        elif groups == 8:\n",
    "            self.stage_out_channels = [-1, 24, 384, 768, 1536]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"\"\"{} groups is not supported for\n",
    "                   1x1 Grouped Convolutions\"\"\".format(num_groups))\n",
    "        \n",
    "        # Stage 1 always has 24 output channels\n",
    "        self.conv1 = conv3x3(self.in_channels,\n",
    "                             self.stage_out_channels[1], # stage 1\n",
    "                             stride=2)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Stage 2\n",
    "        self.stage2 = self._make_stage(2)\n",
    "        # Stage 3\n",
    "        self.stage3 = self._make_stage(3)\n",
    "        # Stage 4\n",
    "        self.stage4 = self._make_stage(4)\n",
    "\n",
    "        # Global pooling:\n",
    "        # Undefined as PyTorch's functional API can be used for on-the-fly\n",
    "        # shape inference if input size is not ImageNet's 224x224\n",
    "\n",
    "        # Fully-connected classification layer\n",
    "        num_inputs = self.stage_out_channels[-1]\n",
    "        self.fc = nn.Linear(num_inputs, self.num_classes)\n",
    "        self.init_params()\n",
    "\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant(m.weight, 1)\n",
    "                init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_stage(self, stage):\n",
    "        modules = OrderedDict()\n",
    "        stage_name = \"ShuffleUnit_Stage{}\".format(stage)\n",
    "        \n",
    "        # First ShuffleUnit in the stage\n",
    "        # 1. non-grouped 1x1 convolution (i.e. pointwise convolution)\n",
    "        #   is used in Stage 2. Group convolutions used everywhere else.\n",
    "        grouped_conv = stage > 2\n",
    "        \n",
    "        # 2. concatenation unit is always used.\n",
    "        first_module = ShuffleUnit(\n",
    "            self.stage_out_channels[stage-1],\n",
    "            self.stage_out_channels[stage],\n",
    "            groups=self.groups,\n",
    "            grouped_conv=grouped_conv,\n",
    "            combine='concat'\n",
    "            )\n",
    "        modules[stage_name+\"_0\"] = first_module\n",
    "\n",
    "        # add more ShuffleUnits depending on pre-defined number of repeats\n",
    "        for i in range(self.stage_repeats[stage-2]):\n",
    "            name = stage_name + \"_{}\".format(i+1)\n",
    "            module = ShuffleUnit(\n",
    "                self.stage_out_channels[stage],\n",
    "                self.stage_out_channels[stage],\n",
    "                groups=self.groups,\n",
    "                grouped_conv=True,\n",
    "                combine='add'\n",
    "                )\n",
    "            modules[name] = module\n",
    "\n",
    "        return nn.Sequential(modules)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "\n",
    "        # global average pooling layer\n",
    "        x = F.avg_pool2d(x, x.data.size()[-2:])\n",
    "        \n",
    "        # flatten for input to fully-connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbParameters(net):\n",
    "    p = 0\n",
    "    for m in net.parameters():\n",
    "        p += m.data.nelement()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #model=SuperMobile.DenseMobile(first_group=True)\n",
    "    print(nbParameters(model))\n",
    "    trans = transforms.Compose(\n",
    "                (\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize(224),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406,0.485, 0.456, 0.406,0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225,0.229, 0.224, 0.225,0.229, 0.224, 0.225]),\n",
    "                )\n",
    "                )\n",
    "\n",
    "    trainDataset = VideoSequenceDataset.VideoDataset(rep=\"/video/GestureSequence/\", SequenceSize=1, batchSize=32, transform=trans, \n",
    "                concat=True, dropFrame=1)\n",
    "    testDataset = VideoSequenceDataset.VideoDataset(rep=\"/video/GestureTest/\", SequenceSize=1, batchSize=16, transform=trans, \n",
    "            concat=True, dropFrame=1)\n",
    "    \n",
    "    \n",
    "    optimizer = optim.SGD( model.parameters(),lr=0.0001, momentum=0.9, weight_decay=0.0005)\n",
    "    train(model,optimizer,trainDataset,testDataset,trans, nbepoch=30, cuda=True)\n",
    "    \n",
    "    torch.save(model, \"gesture_best_1.pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show(make_grid([a[0][4][:3], a[0][4][3:6], a[0][4][6:9]], padding=1, normalize=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "#torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "#image\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "#jupyter\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from __future__ import print_function\n",
    "\n",
    "#os\n",
    "import os\n",
    "import os.path as path\n",
    "import glob\n",
    "\n",
    "#math\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ConvLSTM\n",
    "\n",
    "#### LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t = Variable(torch.rand(1,256,6,6))\n",
    "ht = Variable( torch.zeros(1,128,6,6))\n",
    "ct = Variable( torch.zeros(1,128,6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=1, stride=1, bias=False):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        \n",
    "        self.k = kernel_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.w_i = nn.Parameter(torch.Tensor(4*out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.w_h = nn.Parameter(torch.Tensor(4*out_channels, out_channels, kernel_size, kernel_size))\n",
    "        self.w_c = nn.Parameter(torch.Tensor(3*out_channels, out_channels, kernel_size, kernel_size))\n",
    "\n",
    "        self.bias = bias\n",
    "        if bias:\n",
    "          self.bias_i = Parameter(torch.Tensor(4 * out_channels))\n",
    "          self.bias_h = Parameter(torch.Tensor(4 * out_channels))\n",
    "          self.bias_c = Parameter(torch.Tensor(3 * out_channels))\n",
    "        else:\n",
    "          self.register_parameter('bias_i', None)\n",
    "          self.register_parameter('bias_h', None)\n",
    "          self.register_parameter('bias_c', None)\n",
    "        \n",
    "        self.register_buffer('wc_blank', torch.zeros(out_channels))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        n = 4 * self.in_channels * self.k * self.k\n",
    "        stdv = 1. / math.sqrt(n)\n",
    "        \n",
    "        self.w_i.data.uniform_(-stdv, stdv)\n",
    "        self.w_h.data.uniform_(-stdv, stdv)\n",
    "        self.w_c.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "        if self.bias:\n",
    "            self.bias_i.data.uniform_(-stdv, stdv)\n",
    "            self.bias_h.data.uniform_(-stdv, stdv)\n",
    "            self.bias_c.data.uniform_(-stdv, stdv)\n",
    "\n",
    "        \n",
    "    def forward(self, x, hx):\n",
    "        h, c = hx\n",
    "        wx = F.conv2d(x, self.w_i, self.bias_i, padding=self.padding, stride=self.stride)\n",
    "        wh = F.conv2d(h, self.w_h, self.bias_h, padding=self.padding, stride=self.stride)\n",
    "        wc = F.conv2d(c, self.w_c, self.bias_c, padding=self.padding, stride=self.stride)\n",
    "        \n",
    "        \n",
    "        #wc = torch.cat((wc[:, :2 * self.out_channels], Variable(self.wc_blank).expand(wc.size(0), wc.size(1) // 3, wc.size(2), wc.size(3)), wc[:, 2 * self.out_channels:]), 1)\n",
    "        \n",
    "        i = F.sigmoid(wx[:, :self.out_channels] + wh[:, :self.out_channels] + wc[:, :self.out_channels])\n",
    "        f = F.sigmoid(wx[:, self.out_channels:2*self.out_channels] + wh[:, self.out_channels:2*self.out_channels] \n",
    "                + wc[:, self.out_channels:2*self.out_channels])\n",
    "        g = F.tanh(wx[:, 2*self.out_channels:3*self.out_channels] + wh[:, 2*self.out_channels:3*self.out_channels])\n",
    "        \"\"\"\n",
    "        \n",
    "        wxhc = wx + wh + torch.cat((wc[:, :2 * self.out_channels], Variable(self.wc_blank).expand(wc.size(0), wc.size(1) // 3, wc.size(2), wc.size(3)), wc[:, 2 * self.out_channels:]), 1)\n",
    "    \n",
    "        i = F.sigmoid(wxhc[:, :self.out_channels])\n",
    "        f = F.sigmoid(wxhc[:, self.out_channels:2 * self.out_channels])\n",
    "        g = F.tanh(wxhc[:, 2 * self.out_channels:3 * self.out_channels])\n",
    "        o = F.sigmoid(wxhc[:, 3 * self.out_channels:])\n",
    "        \"\"\"\n",
    "\n",
    "        c_t = f * c + i * g\n",
    "        o_t = F.sigmoid(wx[:, 3*self.out_channels:] + wh[:, 3*self.out_channels:] \n",
    "                        + wc[:, 2*self.out_channels: ]*c_t)\n",
    "        h_t = o_t * F.tanh(c_t)\n",
    "        \n",
    "        return h_t, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Test convLSTM Cell\n",
    "\"\"\"\n",
    "c = ConvLSTMCell(256,128,3)\n",
    "o = c(t, (ht,ct))\n",
    "print(o[0].size() == torch.Size([1,128,6,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "class ConvGRUCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Generate a convolutional GRU cell\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, kernel_size):\n",
    "        super(ConvGRUCell, self).__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.reset_gate = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size, padding=padding)\n",
    "        self.update_gate = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size, padding=padding)\n",
    "        self.out_gate = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size, padding=padding)\n",
    "\n",
    "        init.orthogonal(self.reset_gate.weight)\n",
    "        init.orthogonal(self.update_gate.weight)\n",
    "        init.orthogonal(self.out_gate.weight)\n",
    "        init.constant(self.reset_gate.bias, 0.)\n",
    "        init.constant(self.update_gate.bias, 0.)\n",
    "        init.constant(self.out_gate.bias, 0.)\n",
    "\n",
    "\n",
    "    def forward(self, input_, prev_state):\n",
    "\n",
    "        # get batch and spatial sizes\n",
    "        batch_size = input_.data.size()[0]\n",
    "        spatial_size = input_.data.size()[2:]\n",
    "\n",
    "        # generate empty prev_state, if None is provided\n",
    "        if prev_state is None:\n",
    "            state_size = [batch_size, self.hidden_size] + list(spatial_size)\n",
    "            if torch.cuda.is_available():\n",
    "                prev_state = Variable(torch.zeros(state_size)).cuda()\n",
    "            else:\n",
    "                prev_state = Variable(torch.zeros(state_size))\n",
    "\n",
    "        # data size is [batch, channel, height, width]\n",
    "        stacked_inputs = torch.cat([input_, prev_state], dim=1)\n",
    "        update = F.sigmoid(self.update_gate(stacked_inputs))\n",
    "        reset = F.sigmoid(self.reset_gate(stacked_inputs))\n",
    "        out_inputs = F.tanh(self.out_gate(torch.cat([input_, prev_state * reset], dim=1)))\n",
    "        new_state = prev_state * (1 - update) + out_inputs * update\n",
    "\n",
    "        return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Test GruCell\n",
    "\"\"\"\n",
    "c = ConvGRUCell(256,128,3)\n",
    "o = c(t, Variable( torch.zeros(1,128,6,6)))\n",
    "print(o.size() == torch.Size([1,128,6,6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### ConvRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class convRNN_1_layer(nn.Module):\n",
    "    \"\"\"\n",
    "        Define a RNN with 1 recurrent layer\n",
    "        args : r_type : lstm | gru\n",
    "    \"\"\"\n",
    "    def __init__(self, r_type=\"lstm\"):\n",
    "        super(convRNN_1_layer, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.r_type = r_type\n",
    "        if r_type == \"lstm\":\n",
    "            self.convRNN = ConvLSTMCell(256,128,kernel_size=3, padding=1, stride=1)\n",
    "        elif r_type == \"gru\":\n",
    "            self.convRNN = ConvGRUCell(256,128,3)\n",
    "        else:\n",
    "            print(\"Error : r_type\")\n",
    "            return -1\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(128,6,kernel_size=1, padding=0, stride=1),\n",
    "            nn.AvgPool2d(kernel_size=6, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.r_type==\"lstm\":\n",
    "            outputs = []\n",
    "            ht = Variable( torch.zeros(1,128,6,6))\n",
    "            ct = Variable( torch.zeros(1,128,6,6))\n",
    "\n",
    "            for i in x:\n",
    "                xt = self.features(i)\n",
    "                o, (ht,ct) = self.convRNN(xt, (ht, ct))\n",
    "                outputs.append(o)\n",
    "        \n",
    "            return outputs[-1]\n",
    "        elif self.r_type==\"gru\":\n",
    "            outputs = []\n",
    "            ht = Variable( torch.zeros(1,128,6,6))\n",
    "            \n",
    "            for e,i in enumerate(x):\n",
    "                xt = self.features(i)\n",
    "                ht = self.convRNN(xt, ht)\n",
    "                outputs.append(ht)\n",
    "        \n",
    "            return outputs[-1]\n",
    "        #x = self.classifier(x).squeeze().unsqueeze(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def testconvRNN():\n",
    "    x = Variable(torch.Tensor(3,1,3,225,225))\n",
    "    m = convRNN_1_layer(\"gru\")\n",
    "    print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.0219 -0.0403 -0.1340 -0.1339 -0.0979  0.1944\n",
      "  0.4033  0.5376  0.4314  0.4571  0.5379  0.6263\n",
      "  0.3643  0.5017  0.4147  0.4297  0.4806  0.6200\n",
      "  0.3815  0.5549  0.5013  0.5114  0.5650  0.6845\n",
      "  0.5531  0.7888  0.7034  0.6976  0.7009  0.7421\n",
      "  0.3112  0.2488  0.2539  0.2553  0.2769  0.3705\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.8323 -0.6060 -0.7092 -0.6883 -0.6448 -0.4667\n",
      " -0.7171 -0.3268 -0.3492 -0.3390 -0.2938 -0.4691\n",
      " -0.8129 -0.4514 -0.4954 -0.4771 -0.4078 -0.4968\n",
      " -0.7693 -0.4077 -0.4672 -0.4539 -0.3774 -0.5185\n",
      " -0.8139 -0.4552 -0.5114 -0.5084 -0.4187 -0.5753\n",
      " -0.7730 -0.6422 -0.6360 -0.6432 -0.6081 -0.7433\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.7481  1.2899  1.3627  1.3442  1.2990  0.7380\n",
      "  1.0561  1.8520  1.9480  1.9349  1.9691  1.2708\n",
      "  0.9932  1.8623  1.8975  1.8814  1.8921  1.2319\n",
      "  0.9961  1.8889  1.9104  1.8987  1.9232  1.2420\n",
      "  1.0630  1.9169  1.9595  1.9386  1.9375  1.2786\n",
      "  0.6413  1.0986  1.1128  1.1032  1.1468  0.5575\n",
      "    ... \n",
      "\n",
      "( 0 ,125,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.1914 -0.4069 -0.3027 -0.2993 -0.2897 -0.4295\n",
      " -0.2764 -0.5177 -0.3066 -0.2882 -0.2288 -0.4742\n",
      " -0.3152 -0.5149 -0.3541 -0.3548 -0.3016 -0.4911\n",
      " -0.3438 -0.5595 -0.4208 -0.4013 -0.3591 -0.5263\n",
      " -0.4036 -0.6419 -0.4730 -0.4512 -0.4053 -0.5478\n",
      " -0.1776 -0.4256 -0.3409 -0.3249 -0.2825 -0.1934\n",
      "\n",
      "( 0 ,126,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.3853  0.3249  0.4361  0.4281  0.4217  0.3296\n",
      "  0.5456  0.4648  0.5794  0.5679  0.6331  0.1784\n",
      "  0.4436  0.3132  0.4618  0.4715  0.5272  0.1361\n",
      "  0.4590  0.3402  0.4807  0.4925  0.5385  0.1662\n",
      "  0.5089  0.4033  0.5037  0.5200  0.5702  0.1336\n",
      "  0.2558 -0.1120 -0.0487 -0.0467 -0.0107 -0.5798\n",
      "\n",
      "( 0 ,127,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.0089 -0.3095 -0.1786 -0.1839 -0.1589 -0.2005\n",
      " -0.4651 -1.0707 -1.0057 -1.0318 -1.0518 -0.5131\n",
      " -0.4322 -0.9981 -0.9534 -0.9522 -0.9577 -0.4819\n",
      " -0.4097 -1.0211 -0.9799 -0.9610 -0.9529 -0.4862\n",
      " -0.4415 -1.0598 -1.0411 -1.0240 -0.9982 -0.4685\n",
      " -0.2705 -0.7025 -0.7324 -0.7271 -0.7428 -0.1831\n",
      "[torch.FloatTensor of size 1x128x6x6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testconvRNN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
